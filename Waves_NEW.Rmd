---
title: "Waves_NEW"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(include = FALSE)

# check dependencies
packages = c("readxl",
             "data.table",
             "forecast",
             "ggplot2",
             "xts",
             "tsoutliers",
             "timeDate",
             "cowplot",
             "lmtest",
             "FinTS")
lapply(packages, require, character.only = T)

# load sources
source("paths.R")
source("getData.R")
source("tidyData.R")
source("analyzeData.R")

```

```{r read_data}
if (!file.exists("raw.Rda")){
# link to a 0.6GB file including all data, no texts, in CSV format
        DT <- fread(input = paste(NEW_DATA_PATH, "all_files_no_text.csv", sep = "/"), sep = ",", quote = '"')
} else {
        load("raw.Rda")
}
```

```{r context}
# filter only the context(s) of interest
setkey(DT, "context")
DT <- DT["American Politics",]
```

```{r site}
# read only US websites names
WEBSITES = readWebsites()
# filter DT by WEBSITES
DT <- DT[site %in% WEBSITES$site,]
```

```{r state}
# read states list
STATES = readStates()
# read association of colors to states
COLORS = readColors()
STATES = merge(STATES, COLORS, all = T, by = "state")
# add states (of origin of sources):
setkey(DT,site)
setkey(WEBSITES, site)
DT = merge(DT,WEBSITES, all = F, all.x = T)
```

```{r dates}
# split PUBLISH_DATE to publish_date and publish_time
DT[,publish_time := sapply(strsplit(publish_date,' '), "[", 2)][,publish_date := sapply(strsplit(publish_date,' '), "[", 1)]
DT[, publish_date := as.Date(publish_date)]

# cut dates before 2016:
DT = DT[publish_date >= as.Date("2016-01-01"),]

# get full date range (in days)
DATES <-  getDates(DT)
```

```{r topics}
# extract list of topics in dataset
topicCols <- colnames(DT)[c(11:19, 21:230)]
# select topics with more than 30 data points
relevant <- sapply(seq_along(topicCols), function(i) {length(unique(DT[, get(topicCols[i])]))}) > 30
# set TOPICS for relevant topics only
TOPICS <- topicCols[relevant]

byTopic <- lapply(seq_along(TOPICS), function(i){
        DT[!is.na(get(TOPICS[i])), c("publish_date", "state", "site", "title", TOPICS[i]), with = FALSE]
})
```

```{r counts}

# how many articles per day per site? (returns list of topics)
articleCountPerSite <- lapply(seq_along(TOPICS), function(i){
        getAggregated(byTopic[[i]], grpby = "site")
})
# how many articles per day per state? (returns list of topics)
articleCountPerState <- lapply(seq_along(TOPICS), function(i){
        getAggregated(byTopic[[i]], grpby = "state")
})

# check if there are no rows without topic in DT (sanity)
if (length(DT[, rowSums(.SD, na.rm = T), .SDcols = TOPICS]) == nrow(DT)){
        TotalArticleCountPerSite <- getAggregated(DT, grpby = "site")
        TotalArticleCountPerState <- getAggregated(DT, grpby = "state")
}

# calculate daily Salience per site
salience.site <- lapply(seq_along(TOPICS), function(i){
        tmp <- merge(x = articleCountPerSite[[i]], 
                     y = TotalArticleCountPerSite,
                     by = c("publish_date", "site"),
                     all.x = T)
        tmp[, SaliencePerSite := N.x/N.y]
        return(tmp)
})

# calculate daily Salience per state
salience.state <- lapply(seq_along(TOPICS), function(i){
        tmp <- merge(x = articleCountPerState[[i]], 
                     y = TotalArticleCountPerState,
                     by = c("publish_date", "state"),
                     all.x = T)
        tmp[, SaliencePerState := N.x/N.y]
        return(tmp)
})
```

```{r scores}

# add states (of origin of sources):
setkey(WEBSITES, site)

salience <- lapply(seq_along(TOPICS), function(i){
        setkey(salience.site[[i]], site)
        tmp <- merge(salience.site[[i]], WEBSITES, all = F, all.x = T)
        merge(x = tmp[, .(publish_date, SaliencePerSite, site, state)], y = salience.state[[i]][, .(publish_date, SaliencePerState, state)], by = c("publish_date", "state"))
})

setkey(STATES, color)
# calculate daily averages
lapply(seq_along(TOPICS), function(i){
# salience per site
        salience[[i]][, DailySaliencePerSite := lapply(.SD, mean), by = c("publish_date"), .SDcols = "SaliencePerSite"]
# salience per state
        salience[[i]][, DailySaliencePerState := lapply(.SD, mean), by = c("publish_date"), .SDcols = "SaliencePerState"]
# group sources by states:
        setkey(salience[[i]], "state")
# salience in NATIONWIDE group
        salience[[i]]["Nationwide", DailyNationwideSalience := lapply(.SD, mean), by = c("publish_date"), .SDcols = "SaliencePerSite"]
# salience in LOCAL group
        salience[[i]][!"Nationwide", DailyLocalSalience := lapply(.SD, mean), by = c("publish_date"), .SDcols = "SaliencePerSite"]
# salience in BLUE group
        salience[[i]][STATES["Blue", state], DailyBlueSalience := lapply(.SD, mean), by = c("publish_date"), .SDcols = "SaliencePerSite"]
# salience in RED group
        salience[[i]][STATES["Red", state], DailyRedSalience := lapply(.SD, mean), by = c("publish_date"), .SDcols = "SaliencePerSite"]
# salience in PURPLE group
        salience[[i]][STATES["Purple", state], DailyPurpleSalience := lapply(.SD, mean), by = c("publish_date"), .SDcols = "SaliencePerSite"]
})

byTopic <- lapply(seq_along(TOPICS), function(i){
        merge(x = byTopic[[i]], y = salience[[i]], by = c("publish_date", "site", "state"), all = T)
})

```

```{r padding}
# do padding of dates set missing dates values to 0 (instead fo NA)
byTopic <- lapply(seq_along(TOPICS), function(i){
        setDates(byTopic[[i]], DATES)
})
```

```{r descriptive}
scores <- colnames(byTopic[[i]])[8:14]
SUMMARY <- lapply(seq_along(TOPICS), function(i){
        byTopic[[i]][, sapply(.SD, summary), .SDcols = scores]
})
```

```{r group}
# melt data for plotting with facets:
byTopic_m <- lapply(seq_along(TOPICS), function(i){
        melt(data = byTopic[[i]], measure.vars = scores)
})
```

```{r zeros}
# remove leading zeros
byTopic_m <- lapply(seq_along(TOPICS), function(i){
        byTopic_m[[i]][(byTopic_m[[i]][, cumsum(value), by = variable] != 0)[,2]]
})
```

```{r hist_plot}
HIST <- lapply(seq_along(TOPICS), function(i){
        qplot(data = byTopic_m[[i]], x = value, geom = "histogram") + facet_wrap(~variable, ncol = 3)
})
```

```{r ts_plot}
TS <- lapply(seq_along(TOPICS), function(i){
        qplot(data = byTopic_m[[i]], x = publish_date, y = value, geom = "line") + facet_wrap(~variable, ncol = 1)
})
```

```{r diff_plot}
DIFF <- lapply(seq_along(TOPICS), function(i){
        qplot(data = byTopic_m[[i]], x = publish_date, y = c(0, diff(value)), geom = "line") + facet_wrap(~variable, ncol = 1)
})
```

```{r ts_vs_diff}
TSvsDIFF <- lapply(seq_along(TOPICS), function(i){
        plot_grid(TS[[i]], DIFF[[i]], align='h', labels=c('Original', 'Diff'))
})
```

```{r diff_descriptive}
DIFF_SUMMARY <- lapply(seq_along(TOPICS), function(i){
        summary(byTopic[[i]][, sapply(.SD, diff), .SDcols = scores])
})
```

```{r diff_hist_plot}
DIFF_HIST <- lapply(seq_along(TOPICS), function(i){
        qplot(data = byTopic_m[[i]], x = c(0,diff(value)), geom = "histogram") + facet_wrap(~variable, ncol = 3)
})
```

```{r acf_plot}
ACF <- lapply(seq_along(TOPICS), function(i){
        lapply(scores, function(j){
                Acf(x = byTopic_m[[i]][variable == j, value], plot = F)
        })
})
```

```{r pacf_plot}
ACF <- lapply(seq_along(TOPICS), function(i){
        lapply(scores, function(j){
                Acf(x = byTopic_m[[i]][variable == j, value], 
                    plot = F,
                    type = "partial")
        })
})
```

```{r diff_acf_plot}
ACF <- lapply(seq_along(TOPICS), function(i){
        lapply(scores, function(j){
                Acf(x = byTopic_m[[i]][variable == j, diff(value)], plot = F)
        })
})

```

```{r diff_pacf_plot}
ACF <- lapply(seq_along(TOPICS), function(i){
        lapply(scores, function(j){
                Acf(x = byTopic_m[[i]][variable == j, diff(value)], plot = F, type = "partial")
        })
})

```

```{r weekends}
lapply(seq_along(TOPICS), function(i){
        byTopic_m[[i]][weekdays(publish_date) %in% c("Saturday", "Sunday"), weekend := 1]
        byTopic_m[[i]][, weekend := na.fill(weekend, 0)]
})
```

```{r weekdays}
lapply(seq_along(TOPICS), function(i){
        byTopic_m[[i]][, weekday := weekdays(publish_date)]
        byTopic_m[[i]][, weekday := as.factor(weekday)]
        byTopic_m[[i]][, sort(weekdays(Sys.Date()+0:6))[2:7] := data.table(model.matrix(~weekday)[,2:7])]
        byTopic_m[[i]][, Friday := ifelse(weekday == "Friday", 1, 0)]
})
```

```{r holidays}
HOLIDAYS <- as.Date(holiday(year = 2016, Holiday = c(listHolidays(pattern = "US"), listHolidays(pattern = "Easter"))))
lapply(seq_along(TOPICS), function(i){
        byTopic_m[[i]][publish_date %in% HOLIDAYS, holiday := 1]
        byTopic_m[[i]][, holiday := na.fill(holiday, 0)]
})
```

```{r interesting}
interesting <- c(8, 18, 32, 37)
```

```{r arima_basic}
ARIMA <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
                dt <- unique(byTopic_m[[i]][variable == j, c("publish_date", "value", weekdays(as.Date("2017-07-16")+1:6), "weekend", "holiday")])  
                
                t <- ts(dt[, value])
                # reg <- cbind(seasonaldummy(t), dt[, .(weekend, holiday)])
                
                benchmark <- auto.arima(y = t, d = 1)
                weekday <- auto.arima(y = t, xreg = dt[, c(weekdays(as.Date("2017-07-16")+1:6))], d = 1)
                weekend <- auto.arima(y = t, xreg = dt$weekend, d = 1)
                holiday <- auto.arima(y = t, xreg = dt$holiday, d = 1)

        return(list(benchmark = benchmark, weekday = weekday, weekend = weekend, holiday = holiday))
        })
setNames(byScore, scores)
})

ARIMA <- setNames(ARIMA, TOPICS)
```

```{r arima_seasonal}
S_ARIMA <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
                dt <- unique(byTopic_m[[i]][variable == j, c("publish_date", "value", weekdays(as.Date("2017-07-16")+1:6), "weekend", "holiday")])  
                
                t <- ts(dt[, value], freq = 7)
                # reg <- cbind(seasonaldummy(t), dt[, .(weekend, holiday)])
                benchmark <- tryCatch({
                        auto.arima(y = t, xreg = seasonaldummy(t), d = 1)
                }, error=function(e) e)
                
                weekday <- tryCatch({
                        auto.arima(y = t, xreg = cbind(seasonaldummy(t), dt[, c(weekdays(as.Date("2017-07-16")+1:6))]), d = 1)
                        }, error=function(e) e)
                weekend <- tryCatch({
                        auto.arima(y = t, xreg = cbind(seasonaldummy(t), dt$weekend), d = 1)
                }, error=function(e) e)
                holiday <- tryCatch({
                        auto.arima(y = t, xreg = cbind(seasonaldummy(t), dt$holiday), d = 1)
                }, error=function(e) e)
                
                
        print (paste("finished", j, sep = " "))
        return(list(benchmark = benchmark, weekday = weekday, weekend = weekend, holiday = holiday))
        })
        print (paste("finished", TOPICS[[i]], sep = " "))
setNames(byScore, scores)
})

S_ARIMA <- setNames(S_ARIMA, TOPICS)
```

```{r arima_outliers_basic}
TSO_ARIMA <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
                dt <- unique(byTopic_m[[i]][variable == j, c("publish_date", "value", weekdays(as.Date("2017-07-16")+1:6), "weekend", "holiday")])  
                
                t <- ts(dt[, value])
                # reg <- cbind(seasonaldummy(t), dt[, .(weekend, holiday)])
                
                benchmark <- tryCatch({tso(y = t, args.tsmethod = list(d = 1))}, error=function(e) e)
                weekday <- tryCatch({ tso(y = t, xreg = dt[, c(weekdays(as.Date("2017-07-16")+1:6))], args.tsmethod = list(d = 1))}, error=function(e) e)
                weekend <- tryCatch({ tso(y = t, xreg = dt$weekend, args.tsmethod = list(d = 1))}, error=function(e) e)
                holiday <- tryCatch({ tso(y = t, xreg = dt$holiday, args.tsmethod = list(d = 1))}, error=function(e) e)

        return(list(benchmark = benchmark, weekday = weekday, weekend = weekend, holiday = holiday))
        })
setNames(byScore, scores)
})

TSO_ARIMA <- setNames(TSO_ARIMA, TOPICS)
```

```{r arima_outliers_seasonal}
TSO_S_ARIMA <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
                dt <- unique(byTopic_m[[i]][variable == j, c("publish_date", "value", weekdays(as.Date("2017-07-16")+1:6), "weekend", "holiday")])  
                
                t <- ts(dt[, value], freq = 7)
                # reg <- cbind(seasonaldummy(t), dt[, .(weekend, holiday)])
                
                benchmark <- tryCatch({ tso(y = t, xreg = seasonaldummy(t), args.tsmethod = list(d = 1))}, error=function(e) e)
                weekday <- tryCatch({ tso(y = t, xreg = cbind(seasonaldummy(t), dt[, c(weekdays(as.Date("2017-07-16")+1:6))]), args.tsmethod = list(d = 1))}, error=function(e) e)
                weekend <- tryCatch({ tso(y = t, xreg = cbind(seasonaldummy(t), dt$weekend), args.tsmethod = list(d = 1))}, error=function(e) e)
                holiday <- tryCatch({ tso(y = t, xreg = cbind(seasonaldummy(t), dt$holiday), args.tsmethod = list(d = 1))}, error=function(e) e)

        return(list(benchmark = benchmark, weekday = weekday, weekend = weekend, holiday = holiday))
        })
setNames(byScore, scores)
})

TSO_S_ARIMA <- setNames(TSO_S_ARIMA, TOPICS)
```

```{r serial_test}
SERIALCORR <- lapply(seq_along(TOPICS), function(i){
        r <- lapply(1:7, function(j){
                bgtest(ARIMA[[i]][[j]]$residuals ~ 1)        
        })
        return(r)
})
```

```{r arch_test}
ARCH <- lapply(seq_along(TOPICS), function(i){
        r <- lapply(1:7, function(j){
                ArchTest(ARIMA[[i]][[j]]$residuals)        
        })
        return(r)
})
```

```{r normality_test}
NORM <- lapply(seq_along(TOPICS), function(i){
        r <- lapply(1:7, function(j){
                JarqueBera.test(ARIMA[[i]][[j]]$residuals)        
        })
        return(r)
})
```

```{r residual_acf}
RESID_ACF <- lapply(seq_along(TOPICS), function(i){
        r <- lapply(1:7, function(j){
                Acf(ARIMA[[i]][[j]]$residuals, plot = F)        
        })
        return(r)
})
```

```{r residual_pacf}
RESID_PACF <- lapply(seq_along(TOPICS), function(i){
        r <- lapply(1:7, function(j){
                Acf(ARIMA[[i]][[j]]$residuals, plot = F, type = "partial")        
        })
        return(r)
})
```