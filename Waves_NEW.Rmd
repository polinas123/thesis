---
title: "Waves_NEW"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(message = FALSE)

# check dependencies
packages = c("readxl",
             "data.table",
             "forecast",
             "ggplot2",
             "xts",
             "tsoutliers",
             "timeDate",
             "cowplot",
             "lmtest",
             "FinTS",
             "DescTools")
lapply(packages, require, character.only = T)

# load sources
source("paths.R")
source("getData.R")
source("tidyData.R")
source("analyzeData.R")

```

```{r read_data}
if (!file.exists("raw.Rda")){
# link to a 0.6GB file including all data, no texts, in CSV format
        DT <- fread(input = paste(NEW_DATA_PATH, "all_files_no_text.csv", sep = "/"), sep = ",", quote = '"')
} else {
        load("raw.Rda")
}
```

```{r context}
# filter only the context(s) of interest
setkey(DT, "context")
DT <- DT["American Politics",]
```

```{r site}
# read only US websites names
WEBSITES = readWebsites()
# filter DT by WEBSITES
DT <- DT[site %in% WEBSITES$site,]
```

```{r state}
# read states list
STATES = readStates()
# read association of colors to states
COLORS = readColors()
STATES = merge(STATES, COLORS, all = T, by = "state")
# add states (of origin of sources):
setkey(DT,site)
setkey(WEBSITES, site)
DT = merge(DT,WEBSITES, all = F, all.x = T)
```

```{r dates}
# split PUBLISH_DATE to publish_date and publish_time
DT[,publish_time := sapply(strsplit(publish_date,' '), "[", 2)][,publish_date := sapply(strsplit(publish_date,' '), "[", 1)]
DT[, publish_date := as.Date(publish_date)]

# cut dates before 2016:
DT = DT[publish_date >= as.Date("2016-01-01"),]

# get full date range (in days)
DATES <-  getDates(DT)
```

```{r topics}
# extract list of topics in dataset
topicCols <- colnames(DT)[c(11:19, 21:230)]
# select topics with more than 30 data points
relevant <- sapply(seq_along(topicCols), function(i) {length(unique(DT[, get(topicCols[i])]))}) > 30
# set TOPICS for relevant topics only
TOPICS <- topicCols[relevant]

byTopic <- lapply(seq_along(TOPICS), function(i){
        DT[!is.na(get(TOPICS[i])), c("publish_date", "state", "site", "title", TOPICS[i]), with = FALSE]
})
```

```{r counts}

# how many articles per day per site? (returns list of topics)
articleCountPerSite <- lapply(seq_along(TOPICS), function(i){
        getAggregated(byTopic[[i]], grpby = "site")
})
# how many articles per day per state? (returns list of topics)
articleCountPerState <- lapply(seq_along(TOPICS), function(i){
        getAggregated(byTopic[[i]], grpby = "state")
})

# check if there are no rows without topic in DT (sanity)
if (length(DT[, rowSums(.SD, na.rm = T), .SDcols = TOPICS]) == nrow(DT)){
        TotalArticleCountPerSite <- getAggregated(DT, grpby = "site")
        TotalArticleCountPerState <- getAggregated(DT, grpby = "state")
}

# calculate daily Salience per site
salience.site <- lapply(seq_along(TOPICS), function(i){
        tmp <- merge(x = articleCountPerSite[[i]], 
                     y = TotalArticleCountPerSite,
                     by = c("publish_date", "site"),
                     all.x = T)
        tmp[, SaliencePerSite := N.x/N.y]
        return(tmp)
})

# calculate daily Salience per state
salience.state <- lapply(seq_along(TOPICS), function(i){
        tmp <- merge(x = articleCountPerState[[i]], 
                     y = TotalArticleCountPerState,
                     by = c("publish_date", "state"),
                     all.x = T)
        tmp[, SaliencePerState := N.x/N.y]
        return(tmp)
})
```

```{r scores}

# add states (of origin of sources):
setkey(WEBSITES, site)

salience <- lapply(seq_along(TOPICS), function(i){
        setkey(salience.site[[i]], site)
        tmp <- merge(salience.site[[i]], WEBSITES, all = F, all.x = T)
        merge(x = tmp[, .(publish_date, SaliencePerSite, site, state)], y = salience.state[[i]][, .(publish_date, SaliencePerState, state)], by = c("publish_date", "state"))
})

setkey(STATES, color)
# calculate daily averages
lapply(seq_along(TOPICS), function(i){
# salience per site
        salience[[i]][, DailySaliencePerSite := lapply(.SD, mean), by = c("publish_date"), .SDcols = "SaliencePerSite"]
# salience per state
        salience[[i]][, DailySaliencePerState := lapply(.SD, mean), by = c("publish_date"), .SDcols = "SaliencePerState"]
# group sources by states:
        setkey(salience[[i]], "state")
# salience in NATIONWIDE group
        salience[[i]]["Nationwide", DailyNationwideSalience := lapply(.SD, mean), by = c("publish_date"), .SDcols = "SaliencePerSite"]
# salience in LOCAL group
        salience[[i]][!"Nationwide", DailyLocalSalience := lapply(.SD, mean), by = c("publish_date"), .SDcols = "SaliencePerSite"]
# salience in BLUE group
        salience[[i]][STATES["Blue", state], DailyBlueSalience := lapply(.SD, mean), by = c("publish_date"), .SDcols = "SaliencePerSite"]
# salience in RED group
        salience[[i]][STATES["Red", state], DailyRedSalience := lapply(.SD, mean), by = c("publish_date"), .SDcols = "SaliencePerSite"]
# salience in PURPLE group
        salience[[i]][STATES["Purple", state], DailyPurpleSalience := lapply(.SD, mean), by = c("publish_date"), .SDcols = "SaliencePerSite"]
})

byTopic <- lapply(seq_along(TOPICS), function(i){
        merge(x = byTopic[[i]], y = salience[[i]], by = c("publish_date", "site", "state"), all = T)
})

```

```{r padding}
# do padding of dates set missing dates values to 0 (instead fo NA)
byTopic <- lapply(seq_along(TOPICS), function(i){
        setDates(byTopic[[i]], DATES)
})
```

```{r collection_issues}
# remove "leadin" 1 values, probably introduced due to collection issues
start <- DT[,.N, by = .(publish_date, site)][,.N, by = .(publish_date)][N > 10, publish_date][1]

byTopic <- lapply(seq_along(TOPICS), function(i){
        byTopic[[i]][publish_date >= start,]
})
```


```{r descriptive}
scores <- colnames(byTopic[[1]])[8:14]
SUMMARY <- lapply(seq_along(TOPICS), function(i){
        byTopic[[i]][, sapply(.SD, summary), .SDcols = scores]
})
```

```{r group}
# melt data for plotting with facets:
byTopic_m <- lapply(seq_along(TOPICS), function(i){
        melt(data = byTopic[[i]], measure.vars = scores)
})
```

```{r zeros}
# remove leading zeros
byTopic_m <- lapply(seq_along(TOPICS), function(i){
        byTopic_m[[i]][(byTopic_m[[i]][, cumsum(value), by = variable] != 0)[,2]]
})
```

```{r dim}
byTopic_m <- lapply(seq_along(TOPICS), function(i){
        dt <- lapply(scores, function(j){
                unique(unique(byTopic_m[[i]][variable == j, .(variable, value), by = .(publish_date)])[, value := sum(value), by = .(publish_date)])
        })
return(rbindlist(dt))
})


```


```{r hist_plot}
HIST <- lapply(seq_along(TOPICS), function(i){
        qplot(data = byTopic_m[[i]], x = value, geom = "histogram") + facet_wrap(~variable, ncol = 3)
})
```

```{r ts_plot}
TS <- lapply(seq_along(TOPICS), function(i){
        qplot(data = byTopic_m[[i]], x = publish_date, y = value, geom = "line") + facet_wrap(~variable, ncol = 1)
})
```

```{r diff_plot}
DIFF <- lapply(seq_along(TOPICS), function(i){
        qplot(data = byTopic_m[[i]], x = publish_date, y = c(0, diff(value)), geom = "line") + facet_wrap(~variable, ncol = 1)
})
```

```{r ts_vs_diff}
TSvsDIFF <- lapply(seq_along(TOPICS), function(i){
        plot_grid(TS[[i]], DIFF[[i]], align='h', labels=c('Original', 'Diff'))
})
```

```{r diff_descriptive}


DIFF_SUMMARY <- lapply(seq_along(TOPICS), function(i){
        dt <- lapply(scores, function(j){
                d <- unique(byTopic[[i]][, c("publish_date", j), with = F])[, sapply(.SD, sum), .SDcols = j, by = .(publish_date)]
                summary(diff(d$V1))
        })
})
```

```{r diff_hist_plot}
DIFF_HIST <- lapply(seq_along(TOPICS), function(i){
        qplot(data = byTopic_m[[i]], x = c(0,diff(value)), geom = "histogram") + facet_wrap(~variable, ncol = 3)
})
```

```{r ts_vs_diff_hist}
HIST_TSvsDIFF <- lapply(seq_along(TOPICS), function(i){
        plot_grid(HIST[[i]], DIFF_HIST[[i]], align='h', labels=c('Original', 'Diff'))
})
```

```{r acf_plot}
ACF <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
                Acf(x = byTopic_m[[i]][variable == j, value], plot = F)
        })
        setNames(byScore, scores)
})
ACF <- setNames(ACF, TOPICS)
```

```{r pacf_plot}
PACF <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
                Acf(x = byTopic_m[[i]][variable == j, value], 
                    plot = F,
                    type = "partial")
                
        })
        setNames(byScore, scores)
})
PACF <- setNames(PACF, TOPICS)
```

```{r autocov_plot}
ACOVF <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
                Acf(x = byTopic_m[[i]][variable == j, value], 
                    plot = F,
                    type = "covariance")
                
        })
        setNames(byScore, scores)
})
ACOVF <- setNames(ACOVF, TOPICS)
```


```{r diff_acf_plot}
DIFF_ACF <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
                Acf(x = byTopic_m[[i]][variable == j, diff(value)], plot = F)
        })
        setNames(byScore, scores)
})
DIFF_ACF <- setNames(DIFF_ACF, TOPICS)

```

```{r diff_pacf_plot}
DIFF_PACF <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
                Acf(x = byTopic_m[[i]][variable == j, diff(value)], plot = F, type = "partial")
        })
        setNames(byScore, scores)
})
DIFF_PACF <- setNames(DIFF_PACF, TOPICS)
```

```{r dummy}
dummy <- DATES[publish_date >= start]

disp <- c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "electionDay", "DemEvents", "RepEvents")
```

```{r weekends}
dummy[weekdays(publish_date) %in% c("Saturday", "Sunday"), weekend := 1]
dummy[, weekend := na.fill(weekend, 0)]
```

```{r weekdays}
        dummy[, weekday := weekdays(publish_date)]
        dummy[, weekday := as.factor(weekday)]
        dummy[, sort(weekdays(Sys.Date()+0:6))[2:7] := data.table(model.matrix(~weekday)[,2:7])]
        dummy[, Friday := ifelse(weekday == "Friday", 1, 0)]
```

```{r holidays}
# US holidays without election day
HOLIDAYS <- as.Date(holiday(year = 2016, Holiday = c(listHolidays(pattern = "US")[c(1:4, 6:17)], listHolidays(pattern = "Easter"))))

dummy[publish_date %in% HOLIDAYS, holiday := 1]
dummy[, holiday := na.fill(holiday, 0)]
```

```{r elections+debates}
# US holidays without election day
ELECTIONS <- c(as.Date("2016-02-01"), as.Date("2016-02-09"), as.Date("2016-02-20"), as.Date("2016-03-01"), as.Date("2016-03-05"), as.Date("2016-03-06"), as.Date("2016-03-08"), as.Date("2016-03-12"), as.Date("2016-03-15"), as.Date("2016-03-22"), as.Date("2016-04-05"), as.Date("2016-04-09"), as.Date("2016-04-19"), as.Date("2016-04-26"), as.Date("2016-05-03"), as.Date("2016-05-10"), as.Date("2016-05-17"), as.Date("2016-05-24"), as.Date("2016-06-07"), as.Date("2016-09-26"), as.Date("2016-10-04"), as.Date("2016-10-09"), as.Date("2016-10-19"), as.Date("2016-11-08"))

dummy[publish_date %in% ELECTIONS, electionDay := 1]
dummy[, electionDay := na.fill(electionDay, 0)]
```

```{r democratic}
DEMS <- c(as.Date("2016-02-27"), as.Date("2016-03-21"),  as.Date("2016-03-26"), as.Date("2016-05-07"), as.Date("2016-06-04"), as.Date("2016-06-05"), as.Date("2016-06-14"), as.Date("2016-07-25"), as.Date("2016-07-26"), as.Date("2016-07-27"), as.Date("2016-07-28"))

dummy[publish_date %in% DEMS, DemEvents := 1]
dummy[, DemEvents := na.fill(DemEvents, 0)]
```

```{r republican}
REPS <- c(as.Date("2016-01-28"), as.Date("2016-02-06"),  as.Date("2016-02-23"), as.Date("2016-02-25"), as.Date("2016-03-03"), as.Date("2016-03-10"), as.Date("2016-04-03"), as.Date("2016-04-16"), as.Date("2016-07-18"), as.Date("2016-07-19"), as.Date("2016-07-20"), as.Date("2016-07-21"))

dummy[publish_date %in% REPS, RepEvents := 1]
dummy[, RepEvents := na.fill(RepEvents, 0)]
```

```{r interesting}
interesting <- c(8, 18, 32, 37)
```

```{r weekly}
# how many obs. each day? (given one TS)
cbind(dummy, as.numeric(t[,1]))[V2 > 0, .N, by = weekday]
```

## ARIMA models
# AR(p) Model: 
$x_t$ = $\phi$$x_{t-1}$ + $\epsilon_t$
```{r arima_basic}
ARIMA_BASIC <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
                t <- ts(byTopic_m[[i]][variable == j, value])
                model <- auto.arima(t)
        })
})

S_ARIMA_BASIC <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
                t <- ts(byTopic_m[[i]][variable == j, value], freq = 7)
                model <- auto.arima(t, d = 1)
        })
})

SADJ_ARIMA_BASIC <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
                t <- ts(byTopic_m[[i]][variable == j, value], freq = 7)
                t <- seasadj(stl(t, s.window = "periodic"))
                model <- auto.arima(t, d = 1)
        })
})
```

# regression with ARIMA errors:
```{r RegArima_basic}
ARIMA <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
               
                t <- ts(byTopic_m[[i]][variable == j, value])

                benchmark <- auto.arima(y = t, d = 1, xreg = dummy[, c("electionDay", "DemEvents", "RepEvents")])
                weekday <- auto.arima(y = t, xreg = dummy[, disp, with = F], d = 1)
                weekend <- auto.arima(y = t, xreg = dummy[, .(weekend, electionDay, DemEvents, RepEvents)], d = 1)
                holiday <- auto.arima(y = t, xreg = dummy[, .(holiday, electionDay, DemEvents, RepEvents)], d = 1)

        return(list(benchmark = benchmark, weekday = weekday, weekend = weekend, holiday = holiday))
        })
setNames(byScore, scores)
})

ARIMA <- setNames(ARIMA, TOPICS)
```

```{r arima_seasonal}
S_ARIMA <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
                dt <- unique(byTopic_m[[i]][variable == j, value, by = .(publish_date)])[, sum(value), by = "publish_date"]
               colnames(dt)[2] <- "value"
               
                t <- ts(unique(dt[, .(publish_date, value)])[,2], freq = 7)
                
                benchmark <- tryCatch({
                        auto.arima(y = t, d = 1, xreg = dummy[, c("electionDay", "DemEvents", "RepEvents")])
                }, error=function(e) e)
                
                weekday <- tryCatch({
                        auto.arima(y = t, xreg = cbind(seasonaldummy(t), dummy[, c("electionDay", "DemEvents", "RepEvents")]), d = 1)
                        }, error=function(e) e)
                weekend <- tryCatch({
                        auto.arima(y = t, xreg = dummy[, c("weekend", "electionDay", "DemEvents", "RepEvents")], d = 1)
                }, error=function(e) e)
                holiday <- tryCatch({
                        auto.arima(y = t, xreg = dummy[, c("holiday", "electionDay", "DemEvents", "RepEvents")], d = 1)
                }, error=function(e) e)
                
        return(list(benchmark = benchmark, weekday = weekday, weekend = weekend, holiday = holiday))
        })
        
setNames(byScore, scores)
})

S_ARIMA <- setNames(S_ARIMA, TOPICS)
```

```{r arima_outliers_basic}
TSO_ARIMA <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
                dt <- unique(byTopic_m[[i]][variable == j, c("publish_date", "value", sort(weekdays(Sys.Date()+0:6))[2:7], "weekend", "holiday","electionDay")])  
                
                t <- ts(dt[, value])
                # reg <- cbind(seasonaldummy(t), dt[, .(weekend, holiday)])
                
                benchmark <- tryCatch({tso(y = t, xreg = dt$electionDay, args.tsmethod = list(d = 1))}, error=function(e) e)
                weekday <- tryCatch({ tso(y = t, xreg = dt[, c(sort(weekdays(Sys.Date()+0:6))[2:7], electionDay)], args.tsmethod = list(d = 1))}, error=function(e) e)
                weekend <- tryCatch({ tso(y = t, xreg = dt[,.(weekend,electionDay)], args.tsmethod = list(d = 1))}, error=function(e) e)
                holiday <- tryCatch({ tso(y = t, xreg = dt[,.(holiday, electionDay)], args.tsmethod = list(d = 1))}, error=function(e) e)

        # print (paste("finished", j, sep = " "))
                return(list(benchmark = benchmark, weekday = weekday, weekend = weekend, holiday = holiday))
        })
# print (paste("finished", TOPICS[[i]], sep = " "))
        setNames(byScore, scores)
})

TSO_ARIMA <- setNames(TSO_ARIMA, TOPICS)
```

```{r arima_outliers_seasonal}
TSO_S_ARIMA <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
                dt <- unique(byTopic_m[[i]][variable == j, c("publish_date", "value", sort(weekdays(Sys.Date()+0:6))[2:7], "weekend", "holiday", "electionDay")])  
                
                t <- ts(dt[, value], freq = 7)
                
                benchmark <- tryCatch({ tso(y = t, xreg = dt$electionDay)}, error=function(e) e)
                weekday <- tryCatch({ tso(y = t, xreg = cbind(seasonaldummy(t), dt$electionDay))}, error=function(e) e)
                weekend <- tryCatch({ tso(y = t, xreg = dt[.(weekend, electionDay)])}, error=function(e) e)
                holiday <- tryCatch({ tso(y = t, xreg = dt[.(holiday, electionDay)])}, error=function(e) e)

        return(list(benchmark = benchmark, weekday = weekday, weekend = weekend, holiday = holiday))
        })
setNames(byScore, scores)
})

TSO_S_ARIMA <- setNames(TSO_S_ARIMA, TOPICS)
```

# Diagnostics

```{r tsdiag}
DIAGPLOT <- lapply(seq_along(TOPICS), function(i){
        r <- lapply(1:7, function(j){
                tsdiag(S_ARIMA_BASIC[[i]][[j]])        
        })
        return(r)
})
```


```{r serial_test}
SERIALCORR <- lapply(seq_along(TOPICS), function(i){
        r <- lapply(1:7, function(j){
                bgtest(SADJ_ARIMA_BASIC[[i]][[j]]$residuals ~ 1, order = 7)        
        })
        names(r) <- scores
        return(r)
})
names(SERIALCORR) <- TOPICS
```

```{r arch_test}
ARCH <- lapply(seq_along(TOPICS), function(i){
        r <- lapply(1:7, function(j){
                ArchTest(SADJ_ARIMA_BASIC[[i]][[j]]$residuals, lags = 7)        
        })
        names(r) <- scores
        return(r)
})
names(ARCH) <- TOPICS
```

```{r normality_test}
NORM <- lapply(seq_along(TOPICS), function(i){
        r <- lapply(1:7, function(j){
                JarqueBeraTest(SADJ_ARIMA_BASIC[[i]][[j]]$residuals, robust = T)        
        })
        names(r) <- scores
        return(r)
})
names(NORM) <- TOPICS
```

```{r hypothesis_testing}
DIAGTEST <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(1:7, function(j){
                test <- sum(
                        # NORM[[i]][[j]]$p.value > 0.05,
                        ARCH[[i]][[j]]$p.value > 0.05,
                        SERIALCORR[[i]][[j]]$p.value > 0.05
                )
                if (test == 2) {
                        print(paste(i, TOPICS[i], j, scores[j], sep = " - "))}
                return(test)
        })
        names(byScore) <- scores
})
names(DIAGTEST) <- TOPICS

```

```{r coeftest}
COEF_SIG <- lapply(seq_along(TOPICS), function(i){
        
        byScore <- lapply(seq_along(scores), function(j){
                
                coeftest(SADJ_ARIMA_BASIC[[i]][[j]])
        })
})
```

```{r residual_acf}
RESID_ACF <- lapply(seq_along(TOPICS), function(i){
        r <- lapply(1:7, function(j){
                Acf(SADJ_ARIMA_BASIC[[i]][[j]]$residuals, plot = F)        
        })
        return(r)
})
```

```{r residual_pacf}
RESID_PACF <- lapply(seq_along(TOPICS), function(i){
        r <- lapply(1:7, function(j){
                Acf(SADJ_ARIMA_BASIC[[i]][[j]]$residuals, plot = F, type = "partial")        
        })
        return(r)
})
```

```{r irf}
# irf for MA model
irf <- sapply(0:6, function(i){ (sum(test$coef^i))*sd(test$residuals)})
plot(irf, type = "l")
```

```{r ARp2IRF}
# for p > 2, first  transform AR(p) to AR(1)
# source: https://www3.nd.edu/~esims1/arp_companion.pdf
require(pracma)

ar1 = 0.8
ar2 = 0.6
ar3 = -0.5

C <- compan(c(1, -ar1, -ar2, -ar3))
```

```{r ARp2MAinf}
# calculate IRF using the method described here:
# https://stats.stackexchange.com/questions/171698/how-to-calculate-impulse-responses-for-a-given-autoregressive-process

irf <- function(phi, theta = 0, h = 20){
        
        # check invertability of lag polynomial roots
        # if((!all(abs(polyroot(c(1, -phi)))) < 1)) {
        #         print ("roots NOT OK")
        # }
        
        # if invertible, change AR(p) to MA(inf)
        if(phi){
                # if(!all(abs(phi) < 1)){ # & (all(abs(theta) < 1)))
                # if((!all(abs(polyroot(c(1, -phi)))) > 1))
                print("phi not invertible")}        
        } else {
                # if(!all(abs(theta) < 1)){ # & (all(abs(theta) < 1)))
                # if((!all(abs(polyroot(c(1, -theta)))) < 1))
                print("theta not invertible")}        
        
        
        
        # padding to horizon
        phi <- c(phi, rep(0,h-length(phi)))
        theta <- c(theta, rep(0,h-length(theta)))
        
        result <- NULL
        
        imp0 <- 1
        imp1 <- phi[1] + theta[1]
        imp2 <- sapply(2:h, function(j){
                if (!phi[j-1]){
                        phi[j] + theta[j]
                } else {
                        phi[j-1]^j * (phi[j] + theta[j])
                        # phi[j]^(j-1) * (phi[j] + theta[j])
                }
                
        })
        result <- c(imp0, imp1, imp2)
        
        return(result)
}

GDP <- irf(phi = c(0.22, 0.15))
inflation <- irf(phi = c(0.46, 0.31, 0.16, 0.01))
unemployment <- irf(phi = c(1.58, -0.64))
interest <- irf(phi = c(1.18, -0.23))

plot(GDP, type = "b", col = "red", ylim = range(0:3), ylab = "Response", xlab = "Horizon")
lines(unemployment, type = "b", col = "black")
lines(interest, type = "b", col = "blue")
lines(inflation, type = "b", col = "green")

```

```{r ARsmall2irf}
# calculate IRF using the method described here:
# http://www.econ.ohio-state.edu/dejong/note2.pdf
irf <- function(ar, h = 20){
        result <- NULL
        # if invertible, change AR(p) to MA(inf)
        if(all(abs(ar) < 1)){
                y <- polyroot(c(1, -ar[1], -ar[2]))
                if (all(abs(y) < 1)){
                        lambda <- 1/Re(y)
                        
                        result <- sapply(0:h, function(k){
                                imp <- sapply(0:k, function(j){
                                        lambda[1]^j*lambda[2]^(k-j)
                                })
                                sum(imp)
                        })       
                }
        }
        return(result)
}
```

```{r calculate_irf}
IRF_ARIMA_BASIC <- lapply(seq_along(TOPICS), function(i){
        
        byScore <- lapply(seq_along(scores), function(j){
                print(paste(i,j, swp = ":"))
                tryCatch({
                        imp <- irf(phi = ARIMA_BASIC[[i]][[j]]$model$phi, theta = ARIMA_BASIC[[i]][[j]]$model$theta, h = 330)},
                        error=function(e) e)
                #imp <- imp * sd(ARIMA_BASIC[[i]][[j]]$residuals)
                return(imp)
        })
})

S_IRF_ARIMA_BASIC <- lapply(seq_along(TOPICS), function(i){
        
        byScore <- lapply(seq_along(scores), function(j){
                print(paste("S", i,j, swp = ":"))
                tryCatch({
                        imp <- irf(phi = S_ARIMA_BASIC[[i]][[j]]$model$phi, theta = S_ARIMA_BASIC[[i]][[j]]$model$theta, h = 330)},
                        error=function(e) e)
                # scaling to residual SD
                imp <- imp #* S_ARIMA_BASIC[[i]][[j]]$residuals
                return(imp)
        })
})
```

```{r check_invertability}
INVERTABLE <- lapply(seq_along(TOPICS), function(i){
        
        byScore <- lapply(seq_along(scores), function(j){
                
                phi <- SADJ_ARIMA_BASIC[[i]][[j]]$model$phi
                theta <- SADJ_ARIMA_BASIC[[i]][[j]]$model$theta
                
                if(!is.null(phi)){
                        # if(!all(abs(phi) < 1)){ # & (all(abs(theta) < 1)))
                        if(!all(abs(polyroot(c(1, -phi))) > 1)){
                                print("phi not invertible")
                        }
                }
                else {
                        # if(!all(abs(theta) < 1)){ # & (all(abs(theta) < 1)))
                        if((!all(abs(polyroot(c(1, -theta)))) > 1)){
                                print("theta not invertible")        
                        }
                }
        })
})
```

```{r plot_irf}
# plot non - seasonal IRF
lapply(seq_along(TOPICS), function(i) {plot(c(1, ARMAtoMA(ar = ARIMA_BASIC[[i]][[1]]$model$phi, ma = ARIMA_BASIC[[i]][[1]]$model$theta, lag.max = 30)), type = "b", main = TOPICS[[i]], ylab = "", xlab = "")})
```

```{r plot_s_irf}
# plot seasonal IRF
lapply(seq_along(TOPICS), function(i) {plot(c(1, ARMAtoMA(ar = SADJ_ARIMA_BASIC[[i]][[1]]$model$phi, ma = SADJ_ARIMA_BASIC[[i]][[1]]$model$theta, lag.max = 30)), type = "l", lwd = 2, main = TOPICS[[i]], ylab = "", xlab = "")
        lapply(2:7, function(j){ lines(c(1, ARMAtoMA(ar = SADJ_ARIMA_BASIC[[i]][[j]]$model$phi, ma = SADJ_ARIMA_BASIC[[i]][[j]]$model$theta, lag.max = 30)), col = j) })
        })
```