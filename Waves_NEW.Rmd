---
title: "Waves_NEW"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(message = FALSE)

# check dependencies
packages = c("readxl",
             "data.table",
             "forecast",
             "ggplot2",
             "xts",
             "tsoutliers",
             "timeDate",
             "cowplot",
             "lmtest",
             "FinTS",
             "DescTools")
lapply(packages, require, character.only = T)

# load sources
source("paths.R")
source("getData.R")
source("tidyData.R")
source("analyzeData.R")

```

```{r read_data}
if (!file.exists("raw.Rda")){
# link to a 0.6GB file including all data, no texts, in CSV format
        DT <- fread(input = paste(NEW_DATA_PATH, "all_files_no_text.csv", sep = "/"), sep = ",", quote = '"')
} else {
        load("raw.Rda")
}
```

```{r context}
# filter only the context(s) of interest
setkey(DT, "context")
DT <- DT["American Politics",]
```

```{r site}
# read only US websites names
WEBSITES = readWebsites()
# filter DT by WEBSITES
DT <- DT[site %in% WEBSITES$site,]
```

```{r state}
# read states list
STATES = readStates()
# read association of colors to states
COLORS = readColors()
STATES = merge(STATES, COLORS, all = T, by = "state")
# add states (of origin of sources):
setkey(DT,site)
setkey(WEBSITES, site)
DT = merge(DT,WEBSITES, all = F, all.x = T)
```

```{r dates}
# split PUBLISH_DATE to publish_date and publish_time
DT[,publish_time := sapply(strsplit(publish_date,' '), "[", 2)][,publish_date := sapply(strsplit(publish_date,' '), "[", 1)]
DT[, publish_date := as.Date(publish_date)]

# cut dates before 2016:
DT = DT[publish_date >= as.Date("2016-01-01"),]

# get full date range (in days)
DATES <-  getDates(DT)
```

```{r topics}
# extract list of topics in dataset
topicCols <- colnames(DT)[c(11:19, 21:230)]
# select topics with more than 30 data points
relevant <- sapply(seq_along(topicCols), function(i) {length(unique(DT[, get(topicCols[i])]))}) > 30
# set TOPICS for relevant topics only
TOPICS <- topicCols[relevant]

byTopic <- lapply(seq_along(TOPICS), function(i){
        DT[!is.na(get(TOPICS[i])), c("publish_date", "state", "site", "title", TOPICS[i]), with = FALSE]
})
```

```{r counts}

# how many articles per day per site? (returns list of topics)
articleCountPerSite <- lapply(seq_along(TOPICS), function(i){
        getAggregated(byTopic[[i]], grpby = "site")
})
# how many articles per day per state? (returns list of topics)
articleCountPerState <- lapply(seq_along(TOPICS), function(i){
        getAggregated(byTopic[[i]], grpby = "state")
})

# check if there are no rows without topic in DT (sanity)
if (length(DT[, rowSums(.SD, na.rm = T), .SDcols = TOPICS]) == nrow(DT)){
        TotalArticleCountPerSite <- getAggregated(DT, grpby = "site")
        TotalArticleCountPerState <- getAggregated(DT, grpby = "state")
}

# calculate daily Salience per site
salience.site <- lapply(seq_along(TOPICS), function(i){
        tmp <- merge(x = articleCountPerSite[[i]], 
                     y = TotalArticleCountPerSite,
                     by = c("publish_date", "site"),
                     all.x = T)
        tmp[, SaliencePerSite := N.x/N.y]
        return(tmp)
})

# calculate daily Salience per state
salience.state <- lapply(seq_along(TOPICS), function(i){
        tmp <- merge(x = articleCountPerState[[i]], 
                     y = TotalArticleCountPerState,
                     by = c("publish_date", "state"),
                     all.x = T)
        tmp[, SaliencePerState := N.x/N.y]
        return(tmp)
})
```

```{r scores}

# add states (of origin of sources):
setkey(WEBSITES, site)

salience <- lapply(seq_along(TOPICS), function(i){
        setkey(salience.site[[i]], site)
        tmp <- merge(salience.site[[i]], WEBSITES, all = F, all.x = T)
        merge(x = tmp[, .(publish_date, SaliencePerSite, site, state)], y = salience.state[[i]][, .(publish_date, SaliencePerState, state)], by = c("publish_date", "state"))
})

setkey(STATES, color)
# calculate daily averages
lapply(seq_along(TOPICS), function(i){
# salience per site
        salience[[i]][, DailySaliencePerSite := lapply(.SD, mean), by = c("publish_date"), .SDcols = "SaliencePerSite"]
# salience per state
        salience[[i]][, DailySaliencePerState := lapply(.SD, mean), by = c("publish_date"), .SDcols = "SaliencePerState"]
# group sources by states:
        setkey(salience[[i]], "state")
# salience in NATIONWIDE group
        salience[[i]]["Nationwide", DailyNationwideSalience := lapply(.SD, mean), by = c("publish_date"), .SDcols = "SaliencePerSite"]
# salience in LOCAL group
        salience[[i]][!"Nationwide", DailyLocalSalience := lapply(.SD, mean), by = c("publish_date"), .SDcols = "SaliencePerSite"]
# salience in BLUE group
        salience[[i]][STATES["Blue", state], DailyBlueSalience := lapply(.SD, mean), by = c("publish_date"), .SDcols = "SaliencePerSite"]
# salience in RED group
        salience[[i]][STATES["Red", state], DailyRedSalience := lapply(.SD, mean), by = c("publish_date"), .SDcols = "SaliencePerSite"]
# salience in PURPLE group
        salience[[i]][STATES["Purple", state], DailyPurpleSalience := lapply(.SD, mean), by = c("publish_date"), .SDcols = "SaliencePerSite"]
})

byTopic <- lapply(seq_along(TOPICS), function(i){
        merge(x = byTopic[[i]], y = salience[[i]], by = c("publish_date", "site", "state"), all = T)
})

```

```{r padding}
# do padding of dates set missing dates values to 0 (instead fo NA)
byTopic <- lapply(seq_along(TOPICS), function(i){
        setDates(byTopic[[i]], DATES)
})
```

```{r collection_issues}
# remove "leadin" 1 values, probably introduced due to collection issues
start <- DT[,.N, by = .(publish_date, site)][,.N, by = .(publish_date)][N > 10, publish_date][1]

byTopic <- lapply(seq_along(TOPICS), function(i){
        byTopic[[i]][publish_date >= start,]
})
```


```{r descriptive}
scores <- colnames(byTopic[[i]])[8:14]
SUMMARY <- lapply(seq_along(TOPICS), function(i){
        byTopic[[i]][, sapply(.SD, summary), .SDcols = scores]
})
```

```{r group}
# melt data for plotting with facets:
byTopic_m <- lapply(seq_along(TOPICS), function(i){
        melt(data = byTopic[[i]], measure.vars = scores)
})
```

```{r zeros}
# remove leading zeros
byTopic_m <- lapply(seq_along(TOPICS), function(i){
        byTopic_m[[i]][(byTopic_m[[i]][, cumsum(value), by = variable] != 0)[,2]]
})
```

```{r hist_plot}
HIST <- lapply(seq_along(TOPICS), function(i){
        qplot(data = byTopic_m[[i]], x = value, geom = "histogram") + facet_wrap(~variable, ncol = 3)
})
```

```{r ts_plot}
TS <- lapply(seq_along(TOPICS), function(i){
        qplot(data = byTopic_m[[i]], x = publish_date, y = value, geom = "line") + facet_wrap(~variable, ncol = 1)
})
```

```{r diff_plot}
DIFF <- lapply(seq_along(TOPICS), function(i){
        qplot(data = byTopic_m[[i]], x = publish_date, y = c(0, diff(value)), geom = "line") + facet_wrap(~variable, ncol = 1)
})
```

```{r ts_vs_diff}
TSvsDIFF <- lapply(seq_along(TOPICS), function(i){
        plot_grid(TS[[i]], DIFF[[i]], align='h', labels=c('Original', 'Diff'))
})
```

```{r diff_descriptive}
DIFF_SUMMARY <- lapply(seq_along(TOPICS), function(i){
        summary(byTopic[[i]][, sapply(.SD, diff), .SDcols = scores])
})
```

```{r diff_hist_plot}
DIFF_HIST <- lapply(seq_along(TOPICS), function(i){
        qplot(data = byTopic_m[[i]], x = c(0,diff(value)), geom = "histogram") + facet_wrap(~variable, ncol = 3)
})
```

```{r ts_vs_diff_hist}
HIST_TSvsDIFF <- lapply(seq_along(TOPICS), function(i){
        plot_grid(HIST[[i]], DIFF_HIST[[i]], align='h', labels=c('Original', 'Diff'))
})
```

```{r acf_plot}
ACF <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
                Acf(x = byTopic_m[[i]][variable == j, value], plot = F)
        })
        setNames(byScore, scores)
})
ACF <- setNames(ACF, TOPICS)
```

```{r pacf_plot}
PACF <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
                Acf(x = byTopic_m[[i]][variable == j, value], 
                    plot = F,
                    type = "partial")
                
        })
        setNames(byScore, scores)
})
PACF <- setNames(PACF, TOPICS)
```

```{r diff_acf_plot}
DIFF_ACF <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
                Acf(x = byTopic_m[[i]][variable == j, diff(value)], plot = F)
        })
        setNames(byScore, scores)
})
DIFF_ACF <- setNames(DIFF_ACF, TOPICS)

```

```{r diff_pacf_plot}
DIFF_PACF <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
                Acf(x = byTopic_m[[i]][variable == j, diff(value)], plot = F, type = "partial")
        })
        setNames(byScore, scores)
})
DIFF_PACF <- setNames(DIFF_PACF, TOPICS)
```

```{r dummy}
dummy <- DATES[publish_date >= start]

disp <- c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "electionDay", "DemEvents", "RepEvents")
```

```{r weekends}
dummy[weekdays(publish_date) %in% c("Saturday", "Sunday"), weekend := 1]
dummy[, weekend := na.fill(weekend, 0)]
```

```{r weekdays}
        dummy[, weekday := weekdays(publish_date)]
        dummy[, weekday := as.factor(weekday)]
        dummy[, sort(weekdays(Sys.Date()+0:6))[2:7] := data.table(model.matrix(~weekday)[,2:7])]
        dummy[, Friday := ifelse(weekday == "Friday", 1, 0)]
```

```{r holidays}
# US holidays without election day
HOLIDAYS <- as.Date(holiday(year = 2016, Holiday = c(listHolidays(pattern = "US")[c(1:4, 6:17)], listHolidays(pattern = "Easter"))))

dummy[publish_date %in% HOLIDAYS, holiday := 1]
dummy[, holiday := na.fill(holiday, 0)]
```

```{r elections+debates}
# US holidays without election day
ELECTIONS <- c(as.Date("2016-02-01"), as.Date("2016-02-09"), as.Date("2016-02-20"), as.Date("2016-03-01"), as.Date("2016-03-05"), as.Date("2016-03-06"), as.Date("2016-03-08"), as.Date("2016-03-12"), as.Date("2016-03-15"), as.Date("2016-03-22"), as.Date("2016-04-05"), as.Date("2016-04-09"), as.Date("2016-04-19"), as.Date("2016-04-26"), as.Date("2016-05-03"), as.Date("2016-05-10"), as.Date("2016-05-17"), as.Date("2016-05-24"), as.Date("2016-06-07"), as.Date("2016-09-26"), as.Date("2016-10-04"), as.Date("2016-10-09"), as.Date("2016-10-19"), as.Date("2016-11-08"))

dummy[publish_date %in% ELECTIONS, electionDay := 1]
dummy[, electionDay := na.fill(electionDay, 0)]
```

```{r democratic}
DEMS <- c(as.Date("2016-02-27"), as.Date("2016-03-21"),  as.Date("2016-03-26"), as.Date("2016-05-07"), as.Date("2016-06-04"), as.Date("2016-06-05"), as.Date("2016-06-14"), as.Date("2016-07-25"), as.Date("2016-07-26"), as.Date("2016-07-27"), as.Date("2016-07-28"))

dummy[publish_date %in% DEMS, DemEvents := 1]
dummy[, DemEvents := na.fill(DemEvents, 0)]
```

```{r republican}
REPS <- c(as.Date("2016-01-28"), as.Date("2016-02-06"),  as.Date("2016-02-23"), as.Date("2016-02-25"), as.Date("2016-03-03"), as.Date("2016-03-10"), as.Date("2016-04-03"), as.Date("2016-04-16"), as.Date("2016-07-18"), as.Date("2016-07-19"), as.Date("2016-07-20"), as.Date("2016-07-21"))

dummy[publish_date %in% REPS, RepEvents := 1]
dummy[, RepEvents := na.fill(RepEvents, 0)]
```

```{r interesting}
interesting <- c(8, 18, 32, 37)
```

```{r weekly}
# how many obs. each day? (given one TS)
cbind(dummy, as.numeric(t[,1]))[V2 > 0, .N, by = weekday]
```

```{r arima_basic}
ARIMA <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
                        
               dt <- unique(byTopic_m[[i]][variable == j, value, by = .(publish_date)])[, sum(value), by = "publish_date"]
               colnames(dt)[2] <- "value"
               
                t <- ts(unique(dt[, .(publish_date, value)])[,2])

                benchmark <- auto.arima(y = t, d = 1, xreg = dummy[, c("electionDay", "DemEvents", "RepEvents")])
                weekday <- auto.arima(y = t, xreg = dummy[, disp, with = F], d = 1)
                weekend <- auto.arima(y = t, xreg = dummy[, .(weekend, electionDay, DemEvents, RepEvents)], d = 1)
                holiday <- auto.arima(y = t, xreg = dummy[, .(holiday, electionDay, DemEvents, RepEvents)], d = 1)

        return(list(benchmark = benchmark, weekday = weekday, weekend = weekend, holiday = holiday))
        })
setNames(byScore, scores)
})

ARIMA <- setNames(ARIMA, TOPICS)
```

```{r arima_seasonal}
S_ARIMA <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
                dt <- unique(byTopic_m[[i]][variable == j, value, by = .(publish_date)])[, sum(value), by = "publish_date"]
               colnames(dt)[2] <- "value"
               
                t <- ts(unique(dt[, .(publish_date, value)])[,2], freq = 7)
                
                benchmark <- tryCatch({
                        auto.arima(y = t, d = 1, xreg = dummy[, c("electionDay", "DemEvents", "RepEvents")])
                }, error=function(e) e)
                
                weekday <- tryCatch({
                        auto.arima(y = t, xreg = cbind(seasonaldummy(t), dummy[, c("electionDay", "DemEvents", "RepEvents")]), d = 1)
                        }, error=function(e) e)
                weekend <- tryCatch({
                        auto.arima(y = t, xreg = dummy[, c("weekend", "electionDay", "DemEvents", "RepEvents")], d = 1)
                }, error=function(e) e)
                holiday <- tryCatch({
                        auto.arima(y = t, xreg = dummy[, c("holiday", "electionDay", "DemEvents", "RepEvents")], d = 1)
                }, error=function(e) e)
                
        return(list(benchmark = benchmark, weekday = weekday, weekend = weekend, holiday = holiday))
        })
        
setNames(byScore, scores)
})

S_ARIMA <- setNames(S_ARIMA, TOPICS)
```

```{r arima_outliers_basic}
TSO_ARIMA <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
                dt <- unique(byTopic_m[[i]][variable == j, c("publish_date", "value", sort(weekdays(Sys.Date()+0:6))[2:7], "weekend", "holiday","electionDay")])  
                
                t <- ts(dt[, value])
                # reg <- cbind(seasonaldummy(t), dt[, .(weekend, holiday)])
                
                benchmark <- tryCatch({tso(y = t, xreg = dt$electionDay, args.tsmethod = list(d = 1))}, error=function(e) e)
                weekday <- tryCatch({ tso(y = t, xreg = dt[, c(sort(weekdays(Sys.Date()+0:6))[2:7], electionDay)], args.tsmethod = list(d = 1))}, error=function(e) e)
                weekend <- tryCatch({ tso(y = t, xreg = dt[,.(weekend,electionDay)], args.tsmethod = list(d = 1))}, error=function(e) e)
                holiday <- tryCatch({ tso(y = t, xreg = dt[,.(holiday, electionDay)], args.tsmethod = list(d = 1))}, error=function(e) e)

        # print (paste("finished", j, sep = " "))
                return(list(benchmark = benchmark, weekday = weekday, weekend = weekend, holiday = holiday))
        })
# print (paste("finished", TOPICS[[i]], sep = " "))
        setNames(byScore, scores)
})

TSO_ARIMA <- setNames(TSO_ARIMA, TOPICS)
```

```{r arima_outliers_seasonal}
TSO_S_ARIMA <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
                dt <- unique(byTopic_m[[i]][variable == j, c("publish_date", "value", sort(weekdays(Sys.Date()+0:6))[2:7], "weekend", "holiday", "electionDay")])  
                
                t <- ts(dt[, value], freq = 7)
                
                benchmark <- tryCatch({ tso(y = t, xreg = dt$electionDay)}, error=function(e) e)
                weekday <- tryCatch({ tso(y = t, xreg = cbind(seasonaldummy(t), dt$electionDay))}, error=function(e) e)
                weekend <- tryCatch({ tso(y = t, xreg = dt[.(weekend, electionDay)])}, error=function(e) e)
                holiday <- tryCatch({ tso(y = t, xreg = dt[.(holiday, electionDay)])}, error=function(e) e)

        return(list(benchmark = benchmark, weekday = weekday, weekend = weekend, holiday = holiday))
        })
setNames(byScore, scores)
})

TSO_S_ARIMA <- setNames(TSO_S_ARIMA, TOPICS)
```

```{r serial_test}
SERIALCORR <- lapply(seq_along(TOPICS), function(i){
        r <- lapply(1:7, function(j){
                bgtest(ARIMA[[i]][[j]]$residuals ~ 1)        
        })
        return(r)
})
```

```{r arch_test}
ARCH <- lapply(seq_along(TOPICS), function(i){
        r <- lapply(1:7, function(j){
                ArchTest(ARIMA[[i]][[j]]$residuals)        
        })
        return(r)
})
```

```{r normality_test}
NORM <- lapply(seq_along(TOPICS), function(i){
        r <- lapply(1:7, function(j){
                JarqueBera.test(ARIMA[[i]][[j]]$residuals)        
        })
        return(r)
})
```

```{r residual_acf}
RESID_ACF <- lapply(seq_along(TOPICS), function(i){
        r <- lapply(1:7, function(j){
                Acf(ARIMA[[i]][[j]]$residuals, plot = F)        
        })
        return(r)
})
```

```{r residual_pacf}
RESID_PACF <- lapply(seq_along(TOPICS), function(i){
        r <- lapply(1:7, function(j){
                Acf(ARIMA[[i]][[j]]$residuals, plot = F, type = "partial")        
        })
        return(r)
})
```

```{r irf}
# irf for MA model
irf <- sapply(0:6, function(i){ (sum(test$coef^i))*sd(test$residuals)})
plot(irf, type = "l")
```