---
title: "Waves_NEW"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(message = FALSE)

# check dependencies
packages = c("readxl",
             "data.table",
             "forecast",
             "ggplot2",
             "xts",
             "tsoutliers",
             "timeDate",
             "cowplot",
             "lmtest",
             "FinTS",
             "DescTools")
lapply(packages, require, character.only = T)

# load sources
source("paths.R")
source("getData.R")
source("tidyData.R")
source("analyzeData.R")

```

```{r read_data}
if (!file.exists("raw.Rda")){
# link to a 0.6GB file including all data, no texts, in CSV format
        DT <- fread(input = paste(NEW_DATA_PATH, "all_files_no_text.csv", sep = "/"), sep = ",", quote = '"')
} else {
        load("raw.Rda")
}
```

```{r context}
# filter only the context(s) of interest
setkey(DT, "context")
DT <- DT["American Politics",]
```

```{r site}
# read only US websites names
WEBSITES = readWebsites()
# filter DT by WEBSITES
DT <- DT[site %in% WEBSITES$site,]
```

```{r state}
# read states list
STATES = readStates()
# read association of colors to states
COLORS = readColors()
STATES = merge(STATES, COLORS, all = T, by = "state")
# add states (of origin of sources):
setkey(DT,site)
setkey(WEBSITES, site)
DT = merge(DT,WEBSITES, all = F, all.x = T)
```

```{r dates}
# split PUBLISH_DATE to publish_date and publish_time
DT[,publish_time := sapply(strsplit(publish_date,' '), "[", 2)][,publish_date := sapply(strsplit(publish_date,' '), "[", 1)]
DT[, publish_date := as.Date(publish_date)]

# cut dates before 2016:
DT = DT[publish_date >= as.Date("2016-01-01"),]

# get full date range (in days)
DATES <-  getDates(DT)
```

```{r topics}
# extract list of topics in dataset
topicCols <- colnames(DT)[c(11:19, 21:230)]
# select topics with more than 30 data points
relevant <- sapply(seq_along(topicCols), function(i) {length(unique(DT[, get(topicCols[i])]))}) > 30
# set TOPICS for relevant topics only
TOPICS <- topicCols[relevant]

byTopic <- lapply(seq_along(TOPICS), function(i){
        # DT[!is.na(get(TOPICS[i])), c("publish_date", "state", "site", "title", TOPICS[i]), with = FALSE]
        # cut @ 0.5 threshold
        DT[get(TOPICS[i]) >= 0.5, c("publish_date", "state", "site", "title", TOPICS[i]), with = FALSE]
})
```

```{r counts}

# how many articles per day per site? (returns list of topics)
articleCountPerSite <- lapply(seq_along(TOPICS), function(i){
        getAggregated(byTopic[[i]], grpby = "site")
})
# how many articles per day per state? (returns list of topics)
articleCountPerState <- lapply(seq_along(TOPICS), function(i){
        getAggregated(byTopic[[i]], grpby = "state")
})

articleCount <- lapply(seq_along(TOPICS), function(i){
        getAggregated(byTopic[[i]])
})

# check if there are no rows without topic in DT (sanity)
if (length(DT[, rowSums(.SD, na.rm = T), .SDcols = TOPICS]) == nrow(DT)){
        TotalArticleCountPerSite <- getAggregated(DT, grpby = "site")
        TotalArticleCountPerState <- getAggregated(DT, grpby = "state")
        TotalArticleCount <- getAggregated(DT)
}

# calculate daily Salience per site
salience.local <- lapply(seq_along(TOPICS), function(i){
        tmp <- merge(x = articleCountPerState[[i]], 
                     y = TotalArticleCountPerState,
                     by = c("publish_date", "state"),
                     all.x = T)
        tmp[state != "Nationwide", local := N.x/N.y]
        tmp[state != "Nationwide", daily := lapply(.SD, mean), .SDcols = "local", by = "publish_date"]
        return(unique(tmp[, .(publish_date, daily)]))
})

# calculate daily Salience per state
salience.nationwide <- lapply(seq_along(TOPICS), function(i){
        tmp <- merge(x = articleCountPerSite[[i]],
                     y = TotalArticleCountPerSite,
                     by = c("publish_date", "site"),
                     all.x = T)
        tmp[site %in% WEBSITES[state == "Nationwide", site], nationwide := N.x/N.y]
        tmp[site %in% WEBSITES[state == "Nationwide", site], daily := lapply(.SD, mean), .SDcols = "nationwide", by = "publish_date"]
        return(unique(tmp[, .(publish_date, daily)]))
})

salience.total <- lapply(seq_along(TOPICS), function(i){
        tmp <- merge(x = articleCount[[i]], 
                     y = TotalArticleCount,
                     by = "publish_date",
                     all.x = T)
        tmp[, score := N.x/N.y]
        return(unique(tmp[, .(publish_date, score)]))
})
```

```{r scores}

salience <- lapply(seq_along(TOPICS), function(i){
        tmp <- merge(salience.local[[i]], salience.nationwide[[i]], all = T)
        tmp[, score := lapply(.SD, mean, na.rm = T), .SDcols = "daily", by = "publish_date"]
        return(unique(tmp[, .(publish_date, score)]))
})

byTopic <- lapply(seq_along(TOPICS), function(i){
        merge(x = byTopic[[i]], y = salience[[i]], by = c("publish_date"), all.x = T, all = F)
})

```

```{r padding}
# do padding of dates set missing dates values to 0 (instead fo NA)
byTopic <- lapply(seq_along(TOPICS), function(i){
        setDates(byTopic[[i]], DATES)
        # print (paste("finished topic", i, sep = " "))
        
})

# byTopic <- lapply(seq_along(TOPICS), function(i){
#         lapply(seq(8,14,1), function(j){
#                 set(byTopic[[i]], which(is.na(byTopic[[i]][[j]])), j, 0)
#         })
#         print(i)
# })
        
```

```{r collection_issues}
# remove "leadin" 1 values, probably introduced due to collection issues
start <- DT[,.N, by = .(publish_date, site)][,.N, by = .(publish_date)][N > 10, publish_date][1]

byTopic <- lapply(seq_along(TOPICS), function(i){
        byTopic[[i]][publish_date >= start,]
})
```


```{r descriptive}
SUMMARY <- lapply(seq_along(TOPICS), function(i){
        byTopic[[i]][, sapply(.SD, summary), .SDcols = "score"]
})
```

```{r hist_plot}
HIST <- lapply(seq_along(TOPICS), function(i){
        qplot(data = byTopic[[i]], x = score, geom = "histogram")
})
```

```{r ts_plot}
TS <- lapply(seq_along(TOPICS), function(i){
        qplot(data = byTopic[[i]], x = publish_date, y = score, geom = "line")
})
TS <- setNames(TS, TOPICS)
```

```{r diff_plot}
DIFF <- lapply(seq_along(TOPICS), function(i){
        qplot(data = byTopic[[i]], x = publish_date, y = c(0, diff(score)), geom = "line")
})
```

```{r ts_vs_diff}
TSvsDIFF <- lapply(seq_along(TOPICS), function(i){
        plot_grid(TS[[i]], DIFF[[i]], align='v', labels=c('Original', 'Diff'))
})
```

```{r diff_descriptive}

DIFF_SUMMARY <- lapply(seq_along(TOPICS), function(i){
        
                d <- byTopic[[i]][, diff(score)]
                summary(d)
        
})
```

```{r diff_hist_plot}
DIFF_HIST <- lapply(seq_along(TOPICS), function(i){
        qplot(data = byTopic[[i]], x = c(0,diff(score)), geom = "histogram")
})
```

```{r ts_vs_diff_hist}
HIST_TSvsDIFF <- lapply(seq_along(TOPICS), function(i){
        plot_grid(HIST[[i]], DIFF_HIST[[i]], align='h', labels=c('Original', 'Diff'))
})
```

```{r acf_plot}
ACF <- lapply(seq_along(TOPICS), function(i){
        Acf(x = byTopic[[i]][, score], plot = F)
})
ACF <- setNames(ACF, TOPICS)
```

```{r pacf_plot}
PACF <- lapply(seq_along(TOPICS), function(i){
                Acf(x = byTopic[[i]][, score], 
                    plot = F,
                    type = "partial")
})
PACF <- setNames(PACF, TOPICS)
```

```{r diff_acf_plot}
DIFF_ACF <- lapply(seq_along(TOPICS), function(i){
        Acf(x = byTopic[[i]][, diff(score)], plot = F)
})
DIFF_ACF <- setNames(DIFF_ACF, TOPICS)

```

```{r diff_pacf_plot}
DIFF_PACF <- lapply(seq_along(TOPICS), function(i){
        Acf(x = byTopic[[i]][, diff(score)], plot = F, type = "partial")
})
DIFF_PACF <- setNames(DIFF_PACF, TOPICS)
```

```{r dummy, include=FALSE}
dummy <- DATES[publish_date >= start]

disp <- c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "electionDay", "DemEvents", "RepEvents")
```

```{r weekends, include=FALSE}
dummy[weekdays(publish_date) %in% c("Saturday", "Sunday"), weekend := 1]
dummy[, weekend := na.fill(weekend, 0)]
```

```{r weekdays, include=FALSE}
        dummy[, weekday := weekdays(publish_date)]
        dummy[, weekday := as.factor(weekday)]
        dummy[, sort(weekdays(Sys.Date()+0:6))[2:7] := data.table(model.matrix(~weekday)[,2:7])]
        dummy[, Friday := ifelse(weekday == "Friday", 1, 0)]
```

```{r holidays, include=FALSE}
# US holidays without election day
HOLIDAYS <- as.Date(holiday(year = 2016, Holiday = c(listHolidays(pattern = "US")[c(1:4, 6:17)], listHolidays(pattern = "Easter"))))

dummy[publish_date %in% HOLIDAYS, holiday := 1]
dummy[, holiday := na.fill(holiday, 0)]
```

```{r elections+debates, include=FALSE}
# US holidays without election day
ELECTIONS <- c(as.Date("2016-02-01"), as.Date("2016-02-09"), as.Date("2016-02-20"), as.Date("2016-03-01"), as.Date("2016-03-05"), as.Date("2016-03-06"), as.Date("2016-03-08"), as.Date("2016-03-12"), as.Date("2016-03-15"), as.Date("2016-03-22"), as.Date("2016-04-05"), as.Date("2016-04-09"), as.Date("2016-04-19"), as.Date("2016-04-26"), as.Date("2016-05-03"), as.Date("2016-05-10"), as.Date("2016-05-17"), as.Date("2016-05-24"), as.Date("2016-06-07"), as.Date("2016-09-26"), as.Date("2016-10-04"), as.Date("2016-10-09"), as.Date("2016-10-19"), as.Date("2016-11-08"))

dummy[publish_date %in% ELECTIONS, electionDay := 1]
dummy[, electionDay := na.fill(electionDay, 0)]
```

```{r democratic, include=FALSE}
DEMS <- c(as.Date("2016-02-27"), as.Date("2016-03-21"),  as.Date("2016-03-26"), as.Date("2016-05-07"), as.Date("2016-06-04"), as.Date("2016-06-05"), as.Date("2016-06-14"), as.Date("2016-07-25"), as.Date("2016-07-26"), as.Date("2016-07-27"), as.Date("2016-07-28"))

dummy[publish_date %in% DEMS, DemEvents := 1]
dummy[, DemEvents := na.fill(DemEvents, 0)]
```

```{r republican, include=FALSE}
REPS <- c(as.Date("2016-01-28"), as.Date("2016-02-06"),  as.Date("2016-02-23"), as.Date("2016-02-25"), as.Date("2016-03-03"), as.Date("2016-03-10"), as.Date("2016-04-03"), as.Date("2016-04-16"), as.Date("2016-07-18"), as.Date("2016-07-19"), as.Date("2016-07-20"), as.Date("2016-07-21"))

dummy[publish_date %in% REPS, RepEvents := 1]
dummy[, RepEvents := na.fill(RepEvents, 0)]
```

```{r interesting}
interesting <- c(8, 12, 18, 25, 31, 37, 28, 30)
```

```{r weekly, include=FALSE}
# how many obs. each day? (given one TS)
cbind(dummy, as.numeric(t[,1]))[V2 > 0, .N, by = weekday]
```

## ARIMA models
# AR(p) Model: 
$x_t$ = $\phi$$x_{t-1}$ + $\epsilon_t$

```{r arima_model}
ARIMA_BASIC <- lapply(interesting, function(i){
                model <- NULL
                if (byTopic[[i]][, .N] > 0){
                        t <- ts(unique(byTopic[[i]][, .(publish_date, score)]))[,2]
                        tryCatch({model <- auto.arima(y = t)}, error=function(e) e)
                }
        return(model)
})

ARIMA_BASIC <- setNames(ARIMA_BASIC, TOPICS[interesting])

S_ARIMA_BASIC <- lapply(interesting, function(i){
                model <- NULL
                if (byTopic[[i]][, .N] > 0){
                        t <- ts(unique(byTopic[[i]][, .(publish_date, score)]), freq = 7)[,2]
                        tryCatch({model <- auto.arima(y = t)}, error=function(e) e)
                }
        return(model)
})

S_ARIMA_BASIC <- setNames(ARIMA_BASIC, TOPICS[interesting])

TSO <- lapply(interesting, function(i){
                model <- NULL
                if (byTopic[[i]][, .N] > 0){
                        t <- ts(unique(byTopic[[i]][, .(publish_date, score)]))[,2]
                        tryCatch({model <- tso(y = t)}, error=function(e) e)
                }
        return(model)
})

TSO <- setNames(TSO, TOPICS[interesting])

S_TSO <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
                model <- NULL
                if (byTopic[[i]][, .N] > 0){
                        t <- ts(unique(byTopic[[i]][, .(publish_date, score)]), freq = 7)[,2]
                        tryCatch({model <- tso(y = t)}, error=function(e) e)
                } 
        return(model)
        })
})

S_TSO <- setNames(S_TSO, TOPICS[interesting])
# SADJ_ARIMA_BASIC <- lapply(seq_along(TOPICS), function(i){
#         byScore <- lapply(scores, function(j){
#                 t <- ts(byTopic_m[[i]][variable == j, value], freq = 7)
#                 t <- seasadj(stl(t, s.window = "periodic"))
#                 model <- auto.arima(t, d = 1)
#         })
# })
```

# regression with ARIMA errors:
```{r RegArima_basic, include=FALSE}
ARIMA <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
               
                t <- ts(byTopic_m[[i]][variable == j, value])

                benchmark <- auto.arima(y = t, d = 1, xreg = dummy[, c("electionDay", "DemEvents", "RepEvents")])
                weekday <- auto.arima(y = t, xreg = dummy[, disp, with = F], d = 1)
                weekend <- auto.arima(y = t, xreg = dummy[, .(weekend, electionDay, DemEvents, RepEvents)], d = 1)
                holiday <- auto.arima(y = t, xreg = dummy[, .(holiday, electionDay, DemEvents, RepEvents)], d = 1)

        return(list(benchmark = benchmark, weekday = weekday, weekend = weekend, holiday = holiday))
        })
setNames(byScore, scores)
})

ARIMA <- setNames(ARIMA, TOPICS)
```

```{r arima_seasonal, include=FALSE}
S_ARIMA <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
                dt <- unique(byTopic_m[[i]][variable == j, value, by = .(publish_date)])[, sum(value), by = "publish_date"]
               colnames(dt)[2] <- "value"
               
                t <- ts(unique(dt[, .(publish_date, value)])[,2], freq = 7)
                
                benchmark <- tryCatch({
                        auto.arima(y = t, d = 1, xreg = dummy[, c("electionDay", "DemEvents", "RepEvents")])
                }, error=function(e) e)
                
                weekday <- tryCatch({
                        auto.arima(y = t, xreg = cbind(seasonaldummy(t), dummy[, c("electionDay", "DemEvents", "RepEvents")]), d = 1)
                        }, error=function(e) e)
                weekend <- tryCatch({
                        auto.arima(y = t, xreg = dummy[, c("weekend", "electionDay", "DemEvents", "RepEvents")], d = 1)
                }, error=function(e) e)
                holiday <- tryCatch({
                        auto.arima(y = t, xreg = dummy[, c("holiday", "electionDay", "DemEvents", "RepEvents")], d = 1)
                }, error=function(e) e)
                
        return(list(benchmark = benchmark, weekday = weekday, weekend = weekend, holiday = holiday))
        })
        
setNames(byScore, scores)
})

S_ARIMA <- setNames(S_ARIMA, TOPICS)
```

```{r arima_outliers_basic, include=FALSE}
TSO_ARIMA <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
                dt <- unique(byTopic_m[[i]][variable == j, c("publish_date", "value", sort(weekdays(Sys.Date()+0:6))[2:7], "weekend", "holiday","electionDay")])  
                
                t <- ts(dt[, value])
                # reg <- cbind(seasonaldummy(t), dt[, .(weekend, holiday)])
                
                benchmark <- tryCatch({tso(y = t, xreg = dt$electionDay, args.tsmethod = list(d = 1))}, error=function(e) e)
                weekday <- tryCatch({ tso(y = t, xreg = dt[, c(sort(weekdays(Sys.Date()+0:6))[2:7], electionDay)], args.tsmethod = list(d = 1))}, error=function(e) e)
                weekend <- tryCatch({ tso(y = t, xreg = dt[,.(weekend,electionDay)], args.tsmethod = list(d = 1))}, error=function(e) e)
                holiday <- tryCatch({ tso(y = t, xreg = dt[,.(holiday, electionDay)], args.tsmethod = list(d = 1))}, error=function(e) e)

        # print (paste("finished", j, sep = " "))
                return(list(benchmark = benchmark, weekday = weekday, weekend = weekend, holiday = holiday))
        })
# print (paste("finished", TOPICS[[i]], sep = " "))
        setNames(byScore, scores)
})

TSO_ARIMA <- setNames(TSO_ARIMA, TOPICS)
```

```{r arima_outliers_seasonal, include=FALSE}
TSO_S_ARIMA <- lapply(seq_along(TOPICS), function(i){
        byScore <- lapply(scores, function(j){
                dt <- unique(byTopic_m[[i]][variable == j, c("publish_date", "value", sort(weekdays(Sys.Date()+0:6))[2:7], "weekend", "holiday", "electionDay")])  
                
                t <- ts(dt[, value], freq = 7)
                
                benchmark <- tryCatch({ tso(y = t, xreg = dt$electionDay)}, error=function(e) e)
                weekday <- tryCatch({ tso(y = t, xreg = cbind(seasonaldummy(t), dt$electionDay))}, error=function(e) e)
                weekend <- tryCatch({ tso(y = t, xreg = dt[.(weekend, electionDay)])}, error=function(e) e)
                holiday <- tryCatch({ tso(y = t, xreg = dt[.(holiday, electionDay)])}, error=function(e) e)

        return(list(benchmark = benchmark, weekday = weekday, weekend = weekend, holiday = holiday))
        })
setNames(byScore, scores)
})

TSO_S_ARIMA <- setNames(TSO_S_ARIMA, TOPICS)
```

# Diagnostics

```{r tsdiag}
DIAGPLOT <- lapply(seq_along(interesting), function(i){
        r <- NULL        
        if (!is.null(ARIMA_BASIC[[i]])){
                        r <- tsdiag(ARIMA_BASIC[[i]])
        }
        return(r)
})
DIAGPLOT <- setNames(DIAGPLOT, TOPICS[interesting])

S_DIAGPLOT <- lapply(seq_along(interesting), function(i){
        r <- NULL        
        if (!is.null(S_ARIMA_BASIC[[i]])){
                        r <- tsdiag(S_ARIMA_BASIC[[i]])
        }
        return(r)
})
S_DIAGPLOT <- setNames(S_DIAGPLOT, TOPICS[interesting])



```

```{r fit}
ACTUALvsFITTED <- lapply(seq_along(interesting), function(i){
        r <- NULL        
        if (!is.null(ARIMA_BASIC[[i]])){
                        plot(ARIMA_BASIC[[i]]$x, type = "l", main = TOPICS[interesting[i]])
                        lines(ARIMA_BASIC[[i]]$fitted, col = "red")
        }
        return(r)
})
ACTUALvsFITTED <- setNames(ACTUALvsFITTED, TOPICS[interesting])

S_ACTUALvsFITTED <- lapply(seq_along(interesting), function(i){
        
        plot(S_ARIMA_BASIC[[i]]$x, type = "l", main = TOPICS[interesting[i]])
        lines(S_ARIMA_BASIC[[i]]$fitted, col = "red")
})
S_ACTUALvsFITTED <- setNames(S_ACTUALvsFITTED, TOPICS[interesting])

TSO_ACTUALvsFITTED <- lapply(seq_along(interesting), function(i){
        plot(TSO_BASIC[[i]]$fit$x, type = "l", main = TOPICS[interesting[i]])
        lines(TSO_BASIC[[i]]$fit$fitted, col = "red")
})
TSO_ACTUALvsFITTED <- setNames(TSO_ACTUALvsFITTED, TOPICS[interesting])
```

```{r serial_test}
SERIALCORR <- lapply(seq_along(interesting), function(i){
        bgtest(ARIMA_BASIC[[i]]$residuals ~ 1, order = 7)        
        
})
SERIALCORR <- setNames(SERIALCORR, TOPICS[interesting])
```

```{r arch_test}
ARCH <- lapply(seq_along(interesting), function(i){
        ArchTest(ARIMA_BASIC[[i]]$residuals, lags = 7)        
})
ARCH <- setNames(ARCH, TOPICS[interesting])
```

```{r normality_test}
NORM <- lapply(seq_along(interesting), function(i){
        JarqueBeraTest(ARIMA_BASIC[[i]]$residuals, robust = T)        
        
})
NORM <- setNames(NORM, TOPICS[interesting])
```

```{r hypothesis_testing}
DIAGTEST <- lapply(seq_along(interesting), function(i){
        test <- sum(
                # NORM[[i]][[j]]$p.value > 0.05,
                ARCH[[i]]$p.value > 0.05,
                SERIALCORR[[i]]$p.value > 0.05
        )
        if (test == 2) {
                print(TOPICS[interesting[i]])}
        return(test)
})
DIAGTEST <- setNames(DIAGTEST, TOPICS[interesting])

```

```{r coeftest}
COEF_SIG <- lapply(seq_along(TOPICS), function(i){
        
        byScore <- lapply(seq_along(scores), function(j){
                
                coeftest(S_ARIMA_BASIC[[i]][[j]])
        })
})
```

```{r residual_acf}
RESID_ACF <- lapply(seq_along(TOPICS), function(i){
        r <- lapply(1:7, function(j){
                Acf(S_ARIMA_BASIC[[i]][[j]]$residuals, plot = F)        
        })
        return(r)
})
```

```{r residual_pacf}
RESID_PACF <- lapply(seq_along(TOPICS), function(i){
        r <- lapply(1:7, function(j){
                Acf(S_ARIMA_BASIC[[i]][[j]]$residuals, plot = F, type = "partial")        
        })
        return(r)
})
```

```{r irf}
# irf for MA model
irf <- sapply(0:6, function(i){ (sum(test$coef^i))*sd(test$residuals)})
plot(irf, type = "l")
```

```{r ARp2IRF}
# for p > 2, first  transform AR(p) to AR(1)
# source: https://www3.nd.edu/~esims1/arp_companion.pdf
require(pracma)

ar1 = 0.8
ar2 = 0.6
ar3 = -0.5

C <- compan(c(1, -ar1, -ar2, -ar3))
```

```{r ARp2MAinf}
# calculate IRF using the method described here:
# https://stats.stackexchange.com/questions/171698/how-to-calculate-impulse-responses-for-a-given-autoregressive-process

irf <- function(phi, theta = 0, h = 20){
        
        # check invertability of lag polynomial roots
        # if((!all(abs(polyroot(c(1, -phi)))) < 1)) {
        #         print ("roots NOT OK")
        # }
        
        # if invertible, change AR(p) to MA(inf)
        if(phi){
                # if(!all(abs(phi) < 1)){ # & (all(abs(theta) < 1)))
                # if((!all(abs(polyroot(c(1, -phi)))) > 1))
                print("phi not invertible")}        
        } else {
                # if(!all(abs(theta) < 1)){ # & (all(abs(theta) < 1)))
                # if((!all(abs(polyroot(c(1, -theta)))) < 1))
                print("theta not invertible")}        
        
        
        
        # padding to horizon
        phi <- c(phi, rep(0,h-length(phi)))
        theta <- c(theta, rep(0,h-length(theta)))
        
        result <- NULL
        
        imp0 <- 1
        imp1 <- phi[1] + theta[1]
        imp2 <- sapply(2:h, function(j){
                if (!phi[j-1]){
                        phi[j] + theta[j]
                } else {
                        phi[j-1]^j * (phi[j] + theta[j])
                        # phi[j]^(j-1) * (phi[j] + theta[j])
                }
                
        })
        result <- c(imp0, imp1, imp2)
        
        return(result)
}

GDP <- irf(phi = c(0.22, 0.15))
inflation <- irf(phi = c(0.46, 0.31, 0.16, 0.01))
unemployment <- irf(phi = c(1.58, -0.64))
interest <- irf(phi = c(1.18, -0.23))

plot(GDP, type = "b", col = "red", ylim = range(0:3), ylab = "Response", xlab = "Horizon")
lines(unemployment, type = "b", col = "black")
lines(interest, type = "b", col = "blue")
lines(inflation, type = "b", col = "green")

```

```{r ARsmall2irf}
# calculate IRF using the method described here:
# http://www.econ.ohio-state.edu/dejong/note2.pdf
irf <- function(ar, h = 20){
        result <- NULL
        # if invertible, change AR(p) to MA(inf)
        if(all(abs(ar) < 1)){
                y <- polyroot(c(1, -ar[1], -ar[2]))
                if (all(abs(y) < 1)){
                        lambda <- 1/Re(y)
                        
                        result <- sapply(0:h, function(k){
                                imp <- sapply(0:k, function(j){
                                        lambda[1]^j*lambda[2]^(k-j)
                                })
                                sum(imp)
                        })       
                }
        }
        return(result)
}
```

```{r calculate_irf}
IRF_ARIMA_BASIC <- lapply(seq_along(TOPICS), function(i){
        
        byScore <- lapply(seq_along(scores), function(j){
                print(paste(i,j, swp = ":"))
                tryCatch({
                        imp <- irf(phi = ARIMA_BASIC[[i]][[j]]$model$phi, theta = ARIMA_BASIC[[i]][[j]]$model$theta, h = 330)},
                        error=function(e) e)
                #imp <- imp * sd(ARIMA_BASIC[[i]][[j]]$residuals)
                return(imp)
        })
})

S_IRF_ARIMA_BASIC <- lapply(seq_along(TOPICS), function(i){
        
        byScore <- lapply(seq_along(scores), function(j){
                print(paste("S", i,j, swp = ":"))
                tryCatch({
                        imp <- irf(phi = S_ARIMA_BASIC[[i]][[j]]$model$phi, theta = S_ARIMA_BASIC[[i]][[j]]$model$theta, h = 330)},
                        error=function(e) e)
                # scaling to residual SD
                imp <- imp #* S_ARIMA_BASIC[[i]][[j]]$residuals
                return(imp)
        })
})
```

```{r check_invertability}
INVERTABLE <- lapply(seq_along(TOPICS), function(i){
        
        byScore <- lapply(seq_along(scores), function(j){
                
                phi <- S_ARIMA_BASIC[[i]][[j]]$model$phi
                theta <- S_ARIMA_BASIC[[i]][[j]]$model$theta
                
                if(!is.null(phi)){
                        # if(!all(abs(phi) < 1)){ # & (all(abs(theta) < 1)))
                        if(!all(abs(polyroot(c(1, -phi))) > 1)){
                                print("phi not invertible")
                        }
                }
                else {
                        # if(!all(abs(theta) < 1)){ # & (all(abs(theta) < 1)))
                        if((!all(abs(polyroot(c(1, -theta)))) > 1)){
                                print("theta not invertible")        
                        }
                }
        })
})
```

```{r plot_irf}
# plot non - seasonal IRF
lapply(seq_along(TOPICS), function(i) {plot(c(1, ARMAtoMA(ar = S_ARIMA_BASIC[[i]][[1]]$model$phi, ma = ARIMA_BASIC[[i]][[1]]$model$theta, lag.max = 30)), type = "b", main = TOPICS[[i]], ylab = "", xlab = "")})
```

```{r plot_s_irf}
# plot seasonal IRF
lapply(seq_along(TOPICS), function(i) {plot(c(1, ARMAtoMA(ar = SADJ_ARIMA_BASIC[[i]][[1]]$model$phi, ma = SADJ_ARIMA_BASIC[[i]][[1]]$model$theta, lag.max = 30)), type = "l", lwd = 2, main = TOPICS[[i]], ylab = "", xlab = "")
        lapply(2:7, function(j){ lines(c(1, ARMAtoMA(ar = SADJ_ARIMA_BASIC[[i]][[j]]$model$phi, ma = SADJ_ARIMA_BASIC[[i]][[j]]$model$theta, lag.max = 30)), col = j) })
        })
```